{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPOmqjUh7Bn5"
      },
      "source": [
        "# üõ†Ô∏è **Building Image classification using pretrained CNN models**\n",
        "## 1. Overview\n",
        "This script is designed to fine tune CNNs model on building image dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbEIsKOw7Bn8"
      },
      "source": [
        "# 1. Importing Essential Libraries\n",
        "In this step, we import the necessary tools to build our Deep Learning model.\n",
        "* **TensorFlow & Keras:** The core framework for building and training neural networks.\n",
        "* **Pathlib, OS, Json:** For file management and handling paths.\n",
        "* **CV2, PIL:** For loading and processing images.\n",
        "* **Matplotlib:** For visualizing data and training graphs.\n",
        "* **Numpy:** For handling numerical operations and matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "i-qiYftuqJvn"
      },
      "outputs": [],
      "source": [
        "#Import all the necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from random import choice\n",
        "from pathlib import Path\n",
        "import json\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from random import choice\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "z-bH5WHVrPi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5ffcc2-fe9c-4179-8b12-fbcb0fbea13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "EZWcQFXcsgwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94e9aec-cff0-4bc5-be02-3b59fb5d760f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'drive', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import os\n",
        "os.listdir('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgFQglVI7BoA"
      },
      "source": [
        "# 4. Configuration and Hyperparameters\n",
        "Here we define the \"rules\" for our training process:\n",
        "* **Learning Rate (LR):** Controls how big of a step the model takes when learning.\n",
        "* **Image Shape:** Resizes all input images to `832x535` pixels.\n",
        "* **Batch Size:** Processes `10` images at a time (adjust this based on GPU memory).\n",
        "* **Class Names:** The specific building types we are classifying (`Assam_Type`, `Metal_Sheet`, `RCC`, `Vacant`).\n",
        "* **File Paths:** Defines where to save the best model weights (`.h5` and `.keras`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMog6skbqSQy",
        "outputId": "3a4f84d2-23af-4cc5-d001-6f5b6b6c6983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coarse Learning rates will be chosen from : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n"
          ]
        }
      ],
      "source": [
        "LR = [round(i*0.0001,4) for i in range(1,8)]\n",
        "print(f'Coarse Learning rates will be chosen from : {LR}')\n",
        "lr_tune = 1e-5\n",
        "SEED = 123\n",
        "Save = True\n",
        "batch_size = 10\n",
        "img_shape = (832,535)\n",
        "epochs = epochs_train = 1\n",
        "epochs_tune = 2\n",
        "val_split  = 0.3 # Training vs. Validation split\n",
        "class_names = ['Assam_Type','Metal_Sheet','RCC','Vacant']\n",
        "\n",
        "work_foldr = r'/content/drive/MyDrive/AI4DRR Workshop'\n",
        "\n",
        "Loss='sparse_categorical_crossentropy' # Loss type ##was\n",
        "\n",
        "data_dir = data_dir_train = f'{work_foldr}/Data' # Directory of images\n",
        "\n",
        "dir_txt = f'{work_foldr}/Hyper_p_R_E.json' # Latest Hyper Params are stored here\n",
        "\n",
        "past = f'{work_foldr}'# All previous best are stored here\n",
        "dir_model1 = f'{work_foldr}/model_E.keras'\n",
        "dir_model = f'{work_foldr}/model_E.weights.h5'# The model's weights are stored here ## Use in conjunction with .save_weights() and .load_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gAnfXDo7BoC"
      },
      "source": [
        "# 5. Model Architecture: VGG16 Transfer Learning\n",
        "We are not building a model from scratch. We use **Transfer Learning**:\n",
        "1.  **Base:** We load **VGG16**, a powerful pre-trained model that already knows how to recognize shapes and textures.\n",
        "2.  **Freezing:** We set `layer.trainable = False` to keep VGG16's pre-learned patterns intact.\n",
        "3.  **Head:** We add our own **Dense layers** (classifiers) on top with `Dropout` (to prevent overfitting) and `L2 Regularization` (to keep weights small and stable).\n",
        "4.  **Output:** The final layer has `4` neurons (one for each class) with `softmax` activation to output probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Tj18-2J4qXhq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "def Init_model():\n",
        "    global img_shape\n",
        "    global class_names\n",
        "    classes = len(class_names)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    pretrained_model = tf.keras.applications.Xception(\n",
        "      include_top=False,\n",
        "      weights=\"imagenet\",\n",
        "      input_tensor=None,\n",
        "      input_shape=None,\n",
        "      pooling='avg',\n",
        "      classes=classes,\n",
        "      classifier_activation=\"softmax\",\n",
        "      name=\"xception\",\n",
        ")\n",
        "\n",
        "    for layer in pretrained_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.add(pretrained_model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1xr_f-x7BoD"
      },
      "source": [
        "# 6. Data Pipeline: Splitting and Loading\n",
        "This function (`img_aug`) handles the critical task of preparing the data:\n",
        "1.  **Loading:** Uses `image_dataset_from_directory` to load images and automatically assign labels.\n",
        "2.  **Splitting:** Mathematically divides the data into three sets:\n",
        "    * **Train:** To teach the model.\n",
        "    * **Validation:** To tune the model during training.\n",
        "    * **Test:** To evaluate final performance.\n",
        "3.  **Batching:** Groups images into batches for faster GPU processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FFaaR_olqa8B"
      },
      "outputs": [],
      "source": [
        "def img_aug(data_dir, test_split=0.1):\n",
        "    global SEED, batch_size, val_split, img_shape, class_names\n",
        "\n",
        "    # Calculate the actual validation split considering the test split\n",
        "    actual_val_split = val_split / (1 - test_split)\n",
        "\n",
        "    # Load the full dataset\n",
        "    full_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        seed=SEED,\n",
        "        image_size=img_shape,\n",
        "        batch_size=None,  # Load without batching first\n",
        "        class_names=class_names,\n",
        "    )\n",
        "\n",
        "    # Print dataset size\n",
        "    print(f\"Total number of samples: {tf.data.experimental.cardinality(full_ds).numpy()}\")\n",
        "\n",
        "    # Split the dataset into train+val and test\n",
        "    dataset_size = tf.data.experimental.cardinality(full_ds).numpy()\n",
        "    train_val_size = int((1 - test_split) * dataset_size)\n",
        "    test_size = dataset_size - train_val_size\n",
        "\n",
        "    train_val_ds = full_ds.take(train_val_size)\n",
        "    test_ds = full_ds.skip(train_val_size)\n",
        "\n",
        "    # Split train+val into train and validation\n",
        "    train_size = int((1 - actual_val_split) * train_val_size)\n",
        "    val_size = train_val_size - train_size\n",
        "\n",
        "    train_ds = train_val_ds.take(train_size)\n",
        "    val_ds = train_val_ds.skip(train_size)\n",
        "\n",
        "    # Apply batching\n",
        "    train_ds = train_ds.batch(batch_size)\n",
        "    val_ds = val_ds.batch(batch_size)\n",
        "    test_ds = test_ds.batch(batch_size)\n",
        "\n",
        "    print(f\"Train samples: {train_size}\")\n",
        "    print(f\"Validation samples: {val_size}\")\n",
        "    print(f\"Test samples: {test_size}\")\n",
        "\n",
        "    return train_ds, val_ds, test_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dop04VJQ7BoE"
      },
      "source": [
        "# 7. Helper: Prepare Test Data\n",
        "A utility function to convert the `Test` dataset from a TensorFlow object into standard NumPy arrays. This makes it easier to inspect images and labels manually later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gTGbg7yEqcyB"
      },
      "outputs": [],
      "source": [
        "def prepare_test_data(test_ds):\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "    for images, labels in test_ds:\n",
        "        test_images.append(images.numpy())\n",
        "        test_labels.append(labels.numpy())\n",
        "\n",
        "    test_images = np.concatenate(test_images, axis=0)\n",
        "    test_labels = np.concatenate(test_labels, axis=0)\n",
        "\n",
        "    return test_images, test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpr7IOnn7BoE"
      },
      "source": [
        "# 8. Storing Hyperparameters\n",
        "We organize our key settings into a dictionary. This makes it easier to log experiments or save configurations to a JSON file later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3-cqfYALqeuJ"
      },
      "outputs": [],
      "source": [
        "hyper_params = {\n",
        "    'lr': 0.01 ,#fill as needed if customizing\n",
        "    'batch_size': batch_size ,\n",
        "    'img_shape': img_shape, #(832,535)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j39xk2Q17BoF"
      },
      "source": [
        "# 9. Load and Split the Data\n",
        "We call our `img_aug` function defined earlier.\n",
        "* **Output:** You will see the total count of images and how many were assigned to Training vs. Validation vs. Testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-StFXd4qgty",
        "outputId": "2ac02497-74cc-44e4-eb6c-bf664258f71a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 files belonging to 4 classes.\n",
            "Total number of samples: 120\n",
            "Train samples: 72\n",
            "Validation samples: 36\n",
            "Test samples: 12\n"
          ]
        }
      ],
      "source": [
        "# Load and prepare data\n",
        "train_ds, val_ds, test_ds = img_aug(data_dir)\n",
        "test_images, test_labels = prepare_test_data(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zifT2oB-7BoF"
      },
      "source": [
        "# 10. Compile the Model\n",
        "We initialize the model and prepare it for training.\n",
        "* **Optimizer:** `Adam` (adaptive learning rate).\n",
        "* **Loss Function:** `sparse_categorical_crossentropy` (used because our labels are integers like 0, 1, 2, 3).\n",
        "* **Metrics:** We track `accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wJ_P9fhsudL",
        "outputId": "7a31e397-6b0d-4a8b-a3c6-c43057b9e290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 files belonging to 4 classes.\n",
            "Total number of samples: 120\n",
            "Train samples: 72\n",
            "Validation samples: 36\n",
            "Test samples: 12\n",
            "Model Setup done successfully\n"
          ]
        }
      ],
      "source": [
        "model = Init_model()\n",
        "train_ds,val_ds,test_ds = img_aug(data_dir_train)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate = hyper_params['lr']),\n",
        "    loss = Loss,\n",
        "    metrics=['accuracy'],\n",
        "\n",
        ")\n",
        "print('Model Setup done successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCyL1dTG7BoG"
      },
      "source": [
        "# 11. Initialize History Log\n",
        "We create a list to store the training performance (loss and accuracy) so we can plot graphs later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9ua_-E-LsysE"
      },
      "outputs": [],
      "source": [
        "histories = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrG1MgmD7BoH"
      },
      "source": [
        "# 12. Callbacks: Automation\n",
        "These tools monitor the training:\n",
        "* **EarlyStopping:** If the validation loss doesn't improve for 10 epochs, stop training early to save time.\n",
        "* **ReduceLROnPlateau:** If the model gets stuck, reduce the learning rate to help it find the minimum error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "c0EJA3Fos3l9"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzCZpgp97BoH"
      },
      "source": [
        "# 13. Model Checkpoint\n",
        "This callback saves the **best** version of the model (based on the lowest validation loss). This ensures that even if the model gets worse at the very end of training, we still have the best version saved to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "PbaW3_vJs5d9"
      },
      "outputs": [],
      "source": [
        "model_chk_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = dir_model,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHdc3Hnb7BoI"
      },
      "source": [
        "# 14. Training and Fine-Tuning\n",
        "We run the training loop.\n",
        "* **Strategy:** The loop `range(-1, -2, -1)` unfreezes the **last block** of VGG16.\n",
        "* **Why?** This allows the model to slightly adjust the high-level features of VGG16 to specifically recognize *your* building types, rather than generic objects.\n",
        "* **`model.fit`:** Starts the actual learning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUAnIeems6cL",
        "outputId": "34ae8764-73aa-4a3d-a003-8b16db824b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer -1 unfrozen\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 35s/step - accuracy: 0.2185 - loss: 417.4531 - val_accuracy: 0.1944 - val_loss: 16.6747 - learning_rate: 0.0100\n",
            "Model Trained Succesfully!(?)\n"
          ]
        }
      ],
      "source": [
        "for j in range(-1,-2,-1):\n",
        "    model.get_layer(\"xception\").layers[j].trainable = True\n",
        "    if(j<-1):\n",
        "        model.get_layer(\"xception\").layers[j+1].trainable = False\n",
        "    print(f'layer {j} unfrozen')\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs_train,\n",
        "        callbacks=[early_stopping, lr_scheduler,model_chk_callback]\n",
        "      )\n",
        "    histories.append(history)\n",
        "print('Model Trained Succesfully!(?)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN4Gwr3h7BoI"
      },
      "source": [
        "# 15. Testing the Model (Inference)\n",
        "Now that the model is trained, we test it on unseen data:\n",
        "1.  **Load:** We re-initialize the model structure and load the best saved weights.\n",
        "2.  **Predict:** We pass the test folder images through the model.\n",
        "3.  **Decode:** The model outputs probabilities (e.g., `[0.1, 0.8, 0.05, 0.05]`). We use `np.argmax` to find the highest probability and map it back to the text label (e.g., \"Metal_Sheet\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_fUcgXtkzjBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b760f3e-5473-40ca-b5d4-7ab637698778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16 files.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 43s/step\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/112.jpg ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/113.jpg ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/114.jpg ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/25.JPG ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/26.JPG ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/27.JPG ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/35.JPG ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/36.JPG ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/37.JPG ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/45.jpg ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/46.jpg ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/47.jpg ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/55.jpg ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/56.jpg ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/57.jpg ‚Üí RCC\n",
            "/content/drive/MyDrive/AI4DRR Workshop/Test Data/58.jpg ‚Üí RCC\n"
          ]
        }
      ],
      "source": [
        "# 1. Load model\n",
        "model = Init_model()\n",
        "model.load_weights('/content/drive/MyDrive/AI4DRR Workshop/model_E.weights.h5')\n",
        "\n",
        "# 2. Test folder path\n",
        "test_dir = '/content/drive/MyDrive/AI4DRR Workshop/Test Data'   # <-- change if needed\n",
        "\n",
        "# 3. Load test dataset\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    labels=None,\n",
        "    image_size=img_shape,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 4. Predict\n",
        "predictions = model.predict(test_ds)\n",
        "\n",
        "# 5. Convert predictions to labels\n",
        "predicted_indices = np.argmax(predictions, axis=1)\n",
        "predicted_labels = [class_names[i] for i in predicted_indices]\n",
        "\n",
        "# 6. Get file paths\n",
        "file_paths = test_ds.file_paths\n",
        "\n",
        "# 7. Print results\n",
        "for file, label in zip(file_paths, predicted_labels):\n",
        "    print(f\"{file} ‚Üí {label}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}